const textLayouts = {
  'Artur Żmijewski': `
    <div class="text-layout">
      <h2>Artur Żmijewski</h2>
      <p><em>Signals: How Video Transformed the World</em> (New York: The Museum of Modern Art, 2023)</p>
      <a href="imgs/txts/HR/Zmijewski_Signals_2023_1.jpg" target="_blank">
        <img class="txt-img" src="imgs/txts/LR/Zmijewski_Signals_2023_1_LR.jpeg" alt="Text img view">
      </a>

      <a href="imgs/txts/HR/Zmijewski_Signals_2023_2.jpg" target="_blank">
        <img class="txt-img" src="imgs/txts/LR/Zmijewski_Signals_2023_2_LR.jpeg" alt="Text img view">
      </a>
    </div>
  `,
  'Rebecca Shore': `
    <div class="text-layout">
      <h2>Rebecca Shore</h2>
      <p>“Review: Rebecca Shore at Corbett vs. Dempsey,” <em>Artforum</em>, March 2018</p>

      <a href="imgs/txts/HR/shore_AF_2018_1.jpg" target="_blank">
        <img class="txt-img" src="imgs/txts/LR/shore_AF_2018_1_LR.jpeg" alt="Artforum review">
      </a>

      <a href="imgs/txts/HR/shore_AF_2018_2.jpg" target="_blank">
        <img class="txt-img" src="imgs/txts/LR/shore_AF_2018_2_LR.jpeg" alt="Artforum review">
      </a>

    </div> 
  `,
  'Chto Delat': `
    <div class="text-layout">
      <h2>Chto Delat</h2>
      <p><em>Signals: How Video Transformed the World</em> (New York: The Museum of Modern Art, 2023)</p>

      <a href="imgs/txts/HR/Chto-delat_Signals_2023_1.jpg" target="_blank">
        <img class="txt-img" src="imgs/txts/LR/Chto-delat_Signals_2023_1_LR.jpeg" alt="Text img view">
      </a>

      <a href="imgs/txts/HR/Chto-delat_Signals_2023_2.jpg" target="_blank">
        <img class="txt-img" src="imgs/txts/LR/Chto-delat_Signals_2023_2_LR.jpeg" alt="Text img view">
      </a>

    </div>
  `,
  'Mark Bradford': `
    <div class="text-layout">
      <h2>Mark Bradford</h2>
      <p><em>MoMA Highlights: 365 Works from The Museum of Modern Art</em> (New York: The Museum of Modern Art, 2019)</p>

      <a href="imgs/txts/HR/bradford_MoMA.jpg" target="_blank">
        <img class="txt-img" src="imgs/txts/LR/bradford_MoMA_LR.jpeg" alt="Text img view">
      </a>

    </div>
  `,
  'GaHee Park': `
    <div class="text-layout">
      <h2>GaHee Park</h2>
      <p>“Review: GaHee Park at Motel,” <em>Artforum</em>, January 2018</p>

      <a href="imgs/txts/HR/park_AF_2018.jpg" target="_blank">
        <img class="txt-img" src="imgs/txts/LR/park_AF_2018_LR.jpeg" alt="Text img view">
      </a>

    </div>
  `,
  'Gretchen Bender': `
    <div class="text-layout">
      <h2>Gretchen Bender</h2>
      <p><em>Signals: How Video Transformed the World</em> (New York: The Museum of Modern Art, 2023)</p>

      <a href="imgs/txts/HR/Bender_Signals_MoMA_2023_1.jpg" target="_blank">
        <img class="txt-img" src="imgs/txts/LR/Bender_Signals_MoMA_2023_1_LR.jpeg" alt="Text img view">
      </a>
      <a href="imgs/txts/HR/Bender_Signals_MoMA_2023_2.jpg" target="_blank">
        <img class="txt-img" src="imgs/txts/LR/Bender_Signals_MoMA_2023_2_LR.jpeg" alt="Text img view">
      </a>
    </div>
  `,
  'Ian Cheng': `
    <div class="text-layout">
      <h2>Ian Cheng</h2>
      <p>Curatorial talk, The Museum of Modern Art, New York, June 5, 2019</p>
      <img class="txt-img" src="imgs/txts/HR/efap.jpg" alt="Text img view">
      <p class="img-caption">Installation view of <em>New Order</em>. Ian Cheng, <em>Emissary Forks at Perfection</em>, 2015–16</p>

      <p>What you see playing on the LED wall behind me is not a video, but what the artist Ian Cheng calls a “live simulation.” Cheng built this work, titled <em>Emissary Forks at Perfection</em>, within a multi-platform game engine called Unity, which is typically used by engineers to create mobile games like <em>Angry Birds</em> or <em>Pokémon Go</em>.</p>

      <p>Cheng––who studied both art and cognitive science––began creating his live simulations in 2013. The works emerged from a desire to lose authorial control and develop systems that could generate themselves, to create works that would be alive in some way. So, what you’re seeing here is actually happening for the first time, in real time, and it will never be repeated. If you came back tomorrow, you would see something similar but essentially different and new.</p>

      <p>Using the C# (C Sharp) programming language, Cheng scripts individualized fragments of code that describe a behavior or tendency of an object. He also defines the overall physics of the virtual environment.</p>

      <p>When the simulations are unleashed, these simple properties act on and react to each other and, through this, complexity begins to emerge. The resulting digital realms are non-deterministic and have the capacity to change on their own. As Cheng has described them, the live simulations are “video games that play themselves.”</p>

      <p>The early live simulations were formally exciting, but Cheng began feeling that they were too self-contained. The simulations couldn’t escape being experiments about themselves. They were chaotic in a way that verged on meaninglessness and made it difficult for viewers to engage with on a deeper level. Cheng knew of a tactic used by the science-fiction writer Philip K. Dick when he begins his novels, which is basically to come up with a premise by introducing one simple change from normality––whether that’s taking a pill that shrinks you or makes you taller, or realizing you have the capacity for time-travel.</p>

      <p>Cheng wondered how he could implement this tactic: What could interrupt the open-ended nature of his simulations and offset their chaos? The answer, he realized, were stories. The deterministic force of a narrative agent could confront the simulation’s chaos and inject an element of meaning. Perhaps the introduction of this contradictory element––an agent that is given a goal––might even cause viewers to begin to love and care for the algorithmic system playing out before them. The realization is the genesis of the Emissaries trilogy, of which <em>Emissary Forks at Perfection</em> is the second chapter.</p>

      <p>The Emissaries trilogy unfolds as an exploration of emerging consciousness, a concern that goes back to Cheng’s study of cognitive science, and all three works are in MoMA’s collection. The first chapter is set 3000 years in the past. Viewers encounter an ancient community facing the threat of an imminent volcanic eruption. The second chapter, which I’ll focus on now, jumps thousands of years into the future. The volcanic crater has become a fertile, post-human landscape that is overseen by a disembodied artificial intelligence called Talus Twenty-Nine and its prized Shiba Inu dog.</p>

      <p>Talus has bred the Shiba to evolve the equivalent intelligence of a human. The AI’s presence is signaled by the golden leash that you see some of the Shibas wearing. Talus has been conducting a postmortem of human life. In order to complete its study, it has resurrected an ancient human from the twenty-first century. This is the skeletal figure that you see wandering and flopping around. It turns out that the human was a celebrity when he was alive, and, one day, while on tour, he tumbled out of a helicopter and fell into a copper bog, dead but perfectly preserved, making him the ideal candidate for resurrection.</p>

      <p>Talus nominates his favorite, and most advanced, Shiba to act as Emissary, assigning her the mission to interact with the resurrected celebrity to gather information about his behaviors and memories and to mine him for data. This is why you see the Shiba following the human around. As the Shiba undertakes this mission, she is constantly forking––or replicating––herself. She does this to test different interactions. The forks that fail continue to roam around, while the successful forks will merge and incorporate the learned positive behavior or tendency. Through this, the cute dogs reveal the real-time workings of the machine learning taking place in this simulation. The animation makes this otherwise invisible process, one that is unfolding within the computer hidden in this LED wall, more plainly legible to the people observing it.</p>

      <p>The celebrity can only be resurrected for so long, and begins to decay as the simulation progresses. The rate of decay is signaled by the water levels of the Crater Lake. You might notice the levels fluctuating as you continue watching the screen here. The Shiba keeps interacting with the celebrity, introducing him to objects from the twenty-first century––laptops, red plastic cups––to prompt memories and behaviors and, through this, to collect data for Talus. However, the Shiba is still a dog, and its mission to collect information can be diverted by its innate desire to be a companion to the human. The tension between these impulses is dealt with by forking; contradictory impulses are forked away, so that the mission-oriented Shiba can continue progressing.</p>

      <p>Other objects and forces in the environment can also divert the Shiba from its goal. These diversions impact the duration of the simulation, meaning that the length of the Shiba’s mission is indeterminate. There are an infinite number of ways that the Shiba Emissary’s story can play out, and this process can occur over and over an infinite number of times. Once the simulation begins, it is impossible to tell when it will end, and it will continue cycling over and over, independently.</p>

      <p>The work’s infinite duration, its indeterminacy and autonomous propagation is echoed by Michelle’s decision to install this LED wall in front of the window, a decision made in conversation with the artist. Outside, we see the same basic elements, the same environment, but we could never predict exactly what will take place outside. The cars or people passing by, the DeLillo-like plume of steam, all these environmental elements that will impact what we see but that are unfolding stochastically. There are endlessly forking paths in the real and the digital worlds.</p>

      <p>As you may have begun to notice, Cheng isn’t concerned with using digital technologies to create slick animations. [This different mode of using these tools is on view in the next gallery, where you’ll see an almost hyper-realistic work by Tabor Robak that was also created using the Unity engine.] Rather, Cheng’s interest is in making the behavioral languages that emerge and evolve in the simulation legible. He presents us with just enough visual information to understand what is taking place, and the images are being rendered 30 times per second, in response to the developing algorithm.</p>

      <p>The machine learning, the developing and emerging artificial intelligence is working invisibly and independently of human actors; these cartoonish and often cute forms are the external representation of the machine learning that is taking place. With <em>Emissary Forks at Perfection</em>, and the entire Emissaries trilogy, Cheng is modeling a world of machine cognition, one that ultimately has nothing to do with humans. The algorithm does not run for us, the simulation does not need human intervention to continue unfolding.</p>

    </div>
  `
};
